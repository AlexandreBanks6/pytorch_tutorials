{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attention Basics!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from tqdm.notebook import trange, tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set_root = \"../../datasets\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.MNIST(data_set_root, train=True, download=True, transform=transforms.ToTensor())\n",
    "\n",
    "num_of_examples = 100\n",
    "dataset_tensor = dataset.data.reshape(-1, 28*28)[:num_of_examples].float()\n",
    "dataset_tensor /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing a Dataset\n",
    "At this point we would be familiar with indexing a tensor/array with an integer index!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our index value\n",
    "q_index = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets visualise the image at this index!\n",
    "plt.figure(figsize = (5,5))\n",
    "_ = plt.imshow(dataset_tensor[q_index].reshape(28, 28).numpy(), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing a Dataset with Matrix Multiplication\n",
    "Did you know we can do the same thing, but using Matrix multiplication?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn our index into a ont-hot-coded vector the sample length as the number of samples\n",
    "# we will call this our \"query\" vector (q)\n",
    "q_one_hot_vec = F.one_hot(torch.tensor([q_index]), num_of_examples)\n",
    "\n",
    "# Create a unique one-hot-coded vector for every image in our set\n",
    "# we will call this our \"key\" vector (k)\n",
    "k_one_hot = F.one_hot(torch.arange(num_of_examples), num_of_examples)\n",
    "\n",
    "# Randomly shuffle the keys and dataset to show that we will find the target image\n",
    "# even in a randomly organised dataset\n",
    "rand_perm = torch.randperm(num_of_examples)\n",
    "k_one_hot = k_one_hot[rand_perm]\n",
    "dataset_tensor_random = dataset_tensor[rand_perm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiply our key vector \n",
    "index_map = torch.mm(q_one_hot_vec, k_one_hot.t()).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = torch.mm(index_map, dataset_tensor_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets visualise the image at this index!\n",
    "plt.figure(figsize = (5,5))\n",
    "_ = plt.imshow(output.reshape(28, 28).numpy(), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attention as a \"Soft\" Look-up\n",
    "What if we don't use \"hard\" one-hot coded vectors?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the size for each of the vectors\n",
    "vec_size = 128\n",
    "\n",
    "# Create a random query vector\n",
    "q_random_vec = torch.randn(1, vec_size)\n",
    "\n",
    "# Create a random key vector for each image in the dataset\n",
    "random_keys = torch.randn(num_of_examples, vec_size)\n",
    "\n",
    "# Calculate an \"attention map\" \n",
    "attention_map = torch.mm(q_random_vec, random_keys.t()).float()\n",
    "\n",
    "# Calculate the Softmax over the all over the attention map\n",
    "attention_map = F.softmax(attention_map, 1)\n",
    "\n",
    "# Use the attention map to soft \"index\" over the dataste\n",
    "output = torch.mm(attention_map, dataset_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The largest Softmax value is %f\" % attention_map.max().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets visualise the image we get as a result!\n",
    "plt.figure(figsize = (5,5))\n",
    "_ = plt.imshow(output.reshape(28, 28).numpy(), cmap=\"gray\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
