{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0945ee20",
   "metadata": {},
   "source": [
    "# LSTM, One day at a time!\n",
    "In this Notebook we'll see how the Pytorch LSTM block allows us to pass it the whole data sequence at once. The LSTM block will very quickly process the sequence for us, without having to use a slow Python for loop. Instead of providing a sequence of data ast each time-step (like previous notebooks) we'll simply provide the LSTM a single days worth of data at a time.\n",
    "\n",
    "[<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/9/93/LSTM_Cell.svg/2880px-LSTM_Cell.svg.png\">](LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce37bd68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import Dataset\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from tqdm.notebook import trange, tqdm\n",
    "from Dataset import WeatherDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3afbed5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_file = \"../data/weather.csv\"\n",
    "\n",
    "# Test-Train split on date\n",
    "split_date = pd.to_datetime('2023-01-01')\n",
    "\n",
    "# Number of days in the input sequence\n",
    "day_range = 30\n",
    "\n",
    "# Define the hyperparameters\n",
    "learning_rate = 1e-4\n",
    "\n",
    "nepochs = 500\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "dataset_train = WeatherDataset(dataset_file, day_range=day_range, split_date=split_date, train_test=\"train\")\n",
    "dataset_test = WeatherDataset(dataset_file, day_range=day_range, split_date=split_date, train_test=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e633e62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Number of training examples: {len(dataset_train)}')\n",
    "print(f'Number of testing examples: {len(dataset_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4a4999",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader_train = DataLoader(dataset=dataset_train, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "data_loader_test = DataLoader(dataset=dataset_test, batch_size=batch_size, shuffle=False, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6368437",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 5))\n",
    "_ = plt.title(\"Melbourne Max Daily Temperature (C)\")\n",
    "\n",
    "_ = plt.plot(dataset_train.dataset.index, dataset_train.dataset.values[:, 1])\n",
    "_ = plt.plot(dataset_test.dataset.index, dataset_test.dataset.values[:, 1])\n",
    "\n",
    "_ = plt.legend([\"Train\", \"Test\"])\n",
    "# Note:see here how we can just directly access the data from the dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a793365f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our network class by using the nn.module\n",
    "class ResBlockMLP(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(ResBlockMLP, self).__init__()\n",
    "        self.norm1 = nn.LayerNorm(input_size)\n",
    "        self.fc1 = nn.Linear(input_size, input_size//2)\n",
    "        \n",
    "        self.norm2 = nn.LayerNorm(input_size//2)\n",
    "        self.fc2 = nn.Linear(input_size//2, output_size)\n",
    "        \n",
    "        self.fc3 = nn.Linear(input_size, output_size)\n",
    "\n",
    "        self.act = nn.ELU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.act(self.norm1(x))\n",
    "        skip = self.fc3(x)\n",
    "        \n",
    "        x = self.act(self.norm2(self.fc1(x)))\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x + skip\n",
    "\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, seq_len, output_size, num_blocks=1, hidden_size=128):\n",
    "        super(RNN, self).__init__()\n",
    "        \n",
    "        self.input_mlp = nn.Sequential(nn.Linear(seq_len, 4 * seq_len),\n",
    "                                       nn.ELU(),\n",
    "                                       nn.Linear(4 * seq_len, hidden_size))\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size=hidden_size, hidden_size=hidden_size, num_layers=1, batch_first=True)\n",
    "              \n",
    "        blocks = [ResBlockMLP(hidden_size, hidden_size) for _ in range(num_blocks)]\n",
    "        self.res_blocks = nn.Sequential(*blocks)\n",
    "        \n",
    "        self.fc_out = nn.Linear(hidden_size, output_size)\n",
    "        self.act = nn.ELU()\n",
    "\n",
    "\n",
    "    def forward(self, input_seq, hidden_in, mem_in):\n",
    "        input_vec = self.input_mlp(input_seq)\n",
    "        \n",
    "        output, (hidden_out, mem_out) = self.lstm(input_vec, (hidden_in, mem_in))\n",
    "\n",
    "        x  = self.act(self.res_blocks(output))\n",
    "        \n",
    "        return self.fc_out(x), hidden_out, mem_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bba7dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(0 if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d616ca80",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 128\n",
    "\n",
    "# Create model\n",
    "weather_rnn = RNN(seq_len=2, output_size=2, hidden_size=hidden_size).to(device)\n",
    "\n",
    "# Initialize the optimizer with above parameters\n",
    "optimizer = optim.Adam(weather_rnn.parameters(), lr=learning_rate)\n",
    "\n",
    "# Define the loss function\n",
    "loss_fn = nn.MSELoss()  # mean squared error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036c3e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see how many Parameters our Model has!\n",
    "num_model_params = 0\n",
    "for param in weather_rnn.parameters():\n",
    "    num_model_params += param.flatten().shape[0]\n",
    "\n",
    "print(\"-This Model Has %d (Approximately %d Million) Parameters!\" % (num_model_params, num_model_params//1e6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7feaced",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_loss_logger = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10cefd6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in trange(nepochs, desc=\"Epochs\", leave=False):\n",
    "    weather_rnn.train()\n",
    "    for day, month, data_seq in tqdm(data_loader_train, desc=\"Training\", leave=False):\n",
    "        \n",
    "        # Pytorch allows us to pass the whole sequence of data at a time\n",
    "        # The nn.Linear layers will feed-forward the layers indepenantly (like a batch)\n",
    "        # The LSTM block will process them sequentially\n",
    "        seq_block = data_seq[:, :-1].to(device)\n",
    "        target_seq_block = data_seq[:, 1:].to(device)\n",
    "        hidden = torch.zeros(1, data_seq.shape[0], hidden_size, device=device)\n",
    "        memory = torch.zeros(1, data_seq.shape[0], hidden_size, device=device)\n",
    "\n",
    "        # Letting Pytorchs LSTM to rollout the sequence is a lot faster \n",
    "        # But we can't pass previous predictions into the model at the next timestep\n",
    "        data_pred, hidden, memory = weather_rnn(seq_block, hidden, memory)\n",
    "        loss = loss_fn(data_pred, target_seq_block)\n",
    "            \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        training_loss_logger.append(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd35349",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.figure(figsize=(10, 5))\n",
    "_ = plt.plot(training_loss_logger)\n",
    "_ = plt.title(\"Training Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d369b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tensor = torch.FloatTensor(dataset_test.dataset.values)\n",
    "\n",
    "log_predictions = []\n",
    "weather_rnn.eval()\n",
    "\n",
    "len_input = 30\n",
    "with torch.no_grad():\n",
    "    seq_block = data_tensor[:len_input].unsqueeze(0).to(device)\n",
    "    \n",
    "    hidden = torch.zeros(1, seq_block.shape[0], hidden_size, device=device)\n",
    "    memory = torch.zeros(1, seq_block.shape[0], hidden_size, device=device)\n",
    "    \n",
    "    for i in range(data_tensor.shape[0] - len_input):\n",
    "        data_pred, hidden, memory = weather_rnn(seq_block, hidden, memory)\n",
    "    \n",
    "        seq_block = data_pred[:, -1:, :]\n",
    "        log_predictions.append(data_pred[:, -1, :].cpu())\n",
    "        \n",
    "predictions_cat = torch.cat(log_predictions)\n",
    "un_norm_predictions = (predictions_cat * dataset_test.std) + dataset_test.mean\n",
    "un_norm_data = (data_tensor * dataset_test.std) + dataset_test.mean\n",
    "un_norm_data = un_norm_data[len_input:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3057d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mse = (un_norm_data - un_norm_predictions).pow(2).mean().item()\n",
    "print(\"Test MSE value %.2f\" % test_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aebce83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.figure(figsize=(10, 5))\n",
    "_ = plt.plot(un_norm_data[:, 0])\n",
    "_ = plt.plot(un_norm_predictions[:, 0])\n",
    "_ = plt.title(\"Rainfall (mm)\")\n",
    "\n",
    "_ = plt.legend([\"Ground Truth\", \"Prediction\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22eeee82",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.figure(figsize=(10, 5))\n",
    "_ = plt.plot(un_norm_data[:, 1])\n",
    "_ = plt.plot(un_norm_predictions[:, 1])\n",
    "_ = plt.title(\"Max Daily Temperature (C)\")\n",
    "\n",
    "_ = plt.legend([\"Ground Truth\", \"Prediction\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351df3b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
