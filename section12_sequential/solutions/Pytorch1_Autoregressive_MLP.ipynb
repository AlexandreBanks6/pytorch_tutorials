{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a2aab75",
   "metadata": {},
   "source": [
    "# Predicting Sequential Data\n",
    "In this notebook we'll use an MLP to predict the Max Daily Temperature and Rainfall. <br>\n",
    "The MLP will take in a sequence of days and predict the information for the next day. By setting day_range larger than (days_in + 1) we can see what happens when we feed the models prediction back in as an input during training. The hope is that the model will become robust to any of it's own prediction errors and be able to predict further into the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33bd8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import Dataset\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from tqdm.notebook import trange, tqdm\n",
    "\n",
    "from Dataset import WeatherDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c3a774",
   "metadata": {},
   "source": [
    "### Max Daily Temp and Rainfall Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf91d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_file = \"../data/weather.csv\"\n",
    "\n",
    "# Test-Train split on date\n",
    "split_date = pd.to_datetime('2023-01-01')\n",
    "\n",
    "# Number of days in the input sequence\n",
    "day_range = 15\n",
    "\n",
    "# Number of days the MLP will take in as an input\n",
    "days_in = 14\n",
    "\n",
    "# Days in input seq must be larger than the MLP imput size\n",
    "assert day_range > days_in\n",
    "\n",
    "# Define the hyperparameters\n",
    "learning_rate = 1e-4\n",
    "\n",
    "nepochs = 500\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "dataset_train = WeatherDataset(dataset_file, day_range=day_range, split_date=split_date, train_test=\"train\")\n",
    "dataset_test = WeatherDataset(dataset_file, day_range=day_range, split_date=split_date, train_test=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41db6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Number of training examples: {len(dataset_train)}')\n",
    "print(f'Number of testing examples: {len(dataset_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d20234c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader_train = DataLoader(dataset=dataset_train, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "data_loader_test = DataLoader(dataset=dataset_test, batch_size=batch_size, shuffle=False, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f41162e",
   "metadata": {},
   "source": [
    "### Plot Max Daily Temp Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89562fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 5))\n",
    "_ = plt.title(\"Melbourne Max Daily Temperature (C)\")\n",
    "\n",
    "_ = plt.plot(dataset_train.dataset.index, dataset_train.dataset.values[:, 1])\n",
    "_ = plt.plot(dataset_test.dataset.index, dataset_test.dataset.values[:, 1])\n",
    "\n",
    "_ = plt.legend([\"Train\", \"Test\"])\n",
    "# Note:see here how we can just directly access the data from the dataset class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44235d4b",
   "metadata": {},
   "source": [
    "### Res-MLP Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74f95ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a res-mlp block\n",
    "class ResBlockMLP(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(ResBlockMLP, self).__init__()\n",
    "        self.norm1 = nn.LayerNorm(input_size)\n",
    "        self.fc1 = nn.Linear(input_size, input_size//2)\n",
    "        \n",
    "        self.norm2 = nn.LayerNorm(input_size//2)\n",
    "        self.fc2 = nn.Linear(input_size//2, output_size)\n",
    "        \n",
    "        self.fc3 = nn.Linear(input_size, output_size)\n",
    "\n",
    "        self.act = nn.ELU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.act(self.norm1(x))\n",
    "        skip = self.fc3(x)\n",
    "        \n",
    "        x = self.act(self.norm2(self.fc1(x)))\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x + skip\n",
    "\n",
    "\n",
    "class ResMLP(nn.Module):\n",
    "    def __init__(self, seq_len, output_size, num_blocks=1):\n",
    "        super(ResMLP, self).__init__()\n",
    "        \n",
    "        seq_data_len = seq_len * 2\n",
    "        \n",
    "        self.input_mlp = nn.Sequential(nn.Linear(seq_data_len, 4 * seq_data_len),\n",
    "                                       nn.ELU(),\n",
    "                                       nn.LayerNorm(4 * seq_data_len),\n",
    "                                       nn.Linear(4 * seq_data_len, 128))\n",
    "\n",
    "        blocks = [ResBlockMLP(128, 128) for _ in range(num_blocks)]\n",
    "        self.res_blocks = nn.Sequential(*blocks)\n",
    "        \n",
    "        self.fc_out = nn.Linear(128, output_size)\n",
    "        self.act = nn.ELU()\n",
    "\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        input_seq = input_seq.reshape(input_seq.shape[0], -1)\n",
    "        input_vec = self.input_mlp(input_seq)\n",
    "\n",
    "        x  = self.act(self.res_blocks(input_vec))\n",
    "        \n",
    "        return self.fc_out(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4457f1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(0 if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5360da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "weather_mlp = ResMLP(seq_len=days_in, output_size=2).to(device)\n",
    "\n",
    "# Initialize the optimizer with above parameters\n",
    "optimizer = optim.Adam(weather_mlp.parameters(), lr=learning_rate)\n",
    "\n",
    "# Define the loss function\n",
    "loss_fn = nn.MSELoss()  # mean squared error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b853c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see how many Parameters our Model has!\n",
    "num_model_params = 0\n",
    "for param in weather_mlp.parameters():\n",
    "    num_model_params += param.flatten().shape[0]\n",
    "\n",
    "print(\"-This Model Has %d (Approximately %d Million) Parameters!\" % (num_model_params, num_model_params//1e6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5611b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_loss_logger = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8447afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in trange(nepochs, desc=\"Epochs\", leave=False):\n",
    "    weather_mlp.train()\n",
    "    for day, month, data_seq in tqdm(data_loader_train, desc=\"Training\", leave=False):\n",
    "        \n",
    "        # Index a sub-range of dates to the length of the models input\n",
    "        seq_block = data_seq[:, :days_in].to(device)\n",
    "        loss = 0\n",
    "        for i in range(day_range - days_in):\n",
    "            target_seq_block = data_seq[:, i + days_in].to(device)\n",
    "            \n",
    "            data_pred = weather_mlp(seq_block)\n",
    "            \n",
    "            # Accumulate the loss over the sequence \n",
    "            loss += loss_fn(data_pred, target_seq_block)\n",
    "            \n",
    "            # Remove the oldest date and add the models prediction as the next day predictions\n",
    "            seq_block = torch.cat((seq_block[:, 1:, :], data_pred.unsqueeze(1)), 1).detach()\n",
    "\n",
    "        loss /= i + 1\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        training_loss_logger.append(loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54248736",
   "metadata": {},
   "source": [
    "### Plot Train Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2028eb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.figure(figsize=(10, 5))\n",
    "_ = plt.plot(training_loss_logger)\n",
    "_ = plt.title(\"Training Loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba77028",
   "metadata": {},
   "source": [
    "### Run Autoregressive Prediction Roll-Out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c42c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tensor = torch.FloatTensor(dataset_test.dataset.values)\n",
    "\n",
    "log_predictions = []\n",
    "weather_mlp.eval()\n",
    "with torch.no_grad():\n",
    "    seq_block = data_tensor[:days_in, :].unsqueeze(0).to(device)\n",
    "    for i in range(data_tensor.shape[0] - days_in):\n",
    "        data_pred = weather_mlp(seq_block)\n",
    "        log_predictions.append(data_pred.cpu())\n",
    "\n",
    "        seq_block = torch.cat((seq_block[:, 1:, :], data_pred.unsqueeze(1)), 1)\n",
    "\n",
    "predictions_cat = torch.cat(log_predictions)\n",
    "un_norm_predictions = (predictions_cat * dataset_test.std) + dataset_test.mean\n",
    "un_norm_data = (data_tensor * dataset_test.std) + dataset_test.mean\n",
    "un_norm_data = un_norm_data[days_in:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba949002",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mse = (un_norm_data - un_norm_predictions).pow(2).mean().item()\n",
    "print(\"Test MSE value %.2f\" % test_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b36bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.figure(figsize=(10, 5))\n",
    "_ = plt.plot(un_norm_data[:, 0])\n",
    "_ = plt.plot(un_norm_predictions[:, 0])\n",
    "_ = plt.title(\"Rainfall (mm)\")\n",
    "\n",
    "_ = plt.legend([\"Ground Truth\", \"Prediction\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0b2af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.figure(figsize=(10, 5))\n",
    "_ = plt.plot(un_norm_data[:, 1])\n",
    "_ = plt.plot(un_norm_predictions[:, 1])\n",
    "_ = plt.title(\"Max Daily Temperature (C)\")\n",
    "\n",
    "_ = plt.legend([\"Ground Truth\", \"Prediction\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
