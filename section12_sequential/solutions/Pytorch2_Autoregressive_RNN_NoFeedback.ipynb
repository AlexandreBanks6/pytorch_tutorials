{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Sequential Data With an RNN\n",
    "In this notebook we'll introduce the concept of a [Recurrent Neural Network](https://youtu.be/AsNTP8Kwu80?si=SwLrsvavCfLhgv3V). By allowing the model to pass additional information to itself between time-steps it will be able to pass more information than just previous predictions.\n",
    "\n",
    "[<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/b/b5/Recurrent_neural_network_unfold.svg/2880px-Recurrent_neural_network_unfold.svg.png\">](RNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import Dataset\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from tqdm.notebook import trange, tqdm\n",
    "from Dataset import WeatherDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_file = \"../data/weather.csv\"\n",
    "\n",
    "# Test-Train split on date\n",
    "split_date = pd.to_datetime('2023-01-01')\n",
    "\n",
    "# Number of days in the input sequence\n",
    "day_range = 30\n",
    "\n",
    "# Number of days the MLP will take in as an input\n",
    "days_in = 14\n",
    "\n",
    "# Days in input seq must be larger than the MLP imput size\n",
    "assert day_range > days_in\n",
    "\n",
    "# Define the hyperparameters\n",
    "learning_rate = 1e-4\n",
    "\n",
    "nepochs = 500\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "dataset_train = WeatherDataset(dataset_file, day_range=day_range, split_date=split_date, train_test=\"train\")\n",
    "dataset_test = WeatherDataset(dataset_file, day_range=day_range, split_date=split_date, train_test=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Number of training examples: {len(dataset_train)}')\n",
    "print(f'Number of testing examples: {len(dataset_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader_train = DataLoader(dataset=dataset_train, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "data_loader_test = DataLoader(dataset=dataset_test, batch_size=batch_size, shuffle=False, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 5))\n",
    "_ = plt.title(\"Melbourne Max Daily Temperature (C)\")\n",
    "\n",
    "_ = plt.plot(dataset_train.dataset.index, dataset_train.dataset.values[:, 1])\n",
    "_ = plt.plot(dataset_test.dataset.index, dataset_test.dataset.values[:, 1])\n",
    "\n",
    "_ = plt.legend([\"Train\", \"Test\"])\n",
    "# Note:see here how we can just directly access the data from the dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our network class by using the nn.module\n",
    "class ResBlockMLP(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(ResBlockMLP, self).__init__()\n",
    "        self.norm1 = nn.LayerNorm(input_size)\n",
    "        self.fc1 = nn.Linear(input_size, input_size//2)\n",
    "        \n",
    "        self.norm2 = nn.LayerNorm(input_size//2)\n",
    "        self.fc2 = nn.Linear(input_size//2, output_size)\n",
    "        \n",
    "        self.fc3 = nn.Linear(input_size, output_size)\n",
    "\n",
    "        self.act = nn.ELU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.act(self.norm1(x))\n",
    "        skip = self.fc3(x)\n",
    "        \n",
    "        x = self.act(self.norm2(self.fc1(x)))\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x + skip\n",
    "\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, seq_len, output_size, num_blocks=1, buffer_size=128):\n",
    "        super(RNN, self).__init__()\n",
    "        \n",
    "        seq_data_len = seq_len * 2\n",
    "\n",
    "        self.input_mlp = nn.Sequential(nn.Linear(seq_data_len, 4 * seq_data_len),\n",
    "                                       nn.ELU(),\n",
    "                                       nn.Linear(4 * seq_data_len, 128),\n",
    "                                       nn.ELU(),)\n",
    "        \n",
    "        self.rnn = nn.Linear(256, 128)\n",
    "        \n",
    "        blocks = [ResBlockMLP(128, 128) for _ in range(num_blocks)]\n",
    "        self.res_blocks = nn.Sequential(*blocks)\n",
    "        \n",
    "        self.fc_out = nn.Linear(128, output_size)\n",
    "        self.fc_buffer = nn.Linear(128, buffer_size)\n",
    "        self.act = nn.ELU()\n",
    "\n",
    "\n",
    "    def forward(self, input_seq, buffer_in):\n",
    "        input_seq = input_seq.reshape(input_seq.shape[0], -1)\n",
    "        input_vec = self.input_mlp(input_seq)\n",
    "        \n",
    "        # Concatenate the previous step buffer\n",
    "        x_cat = torch.cat((buffer_in, input_vec), 1)\n",
    "        x = self.rnn(x_cat)\n",
    "\n",
    "        x  = self.act(self.res_blocks(x))\n",
    "        \n",
    "        return self.fc_out(x), torch.tanh(self.fc_buffer(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(0 if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer_size = 128\n",
    "\n",
    "# Create model\n",
    "weather_rnn = RNN(seq_len=days_in, output_size=2, buffer_size=buffer_size).to(device)\n",
    "\n",
    "# Initialize the optimizer with above parameters\n",
    "optimizer = optim.Adam(weather_rnn.parameters(), lr=learning_rate)\n",
    "\n",
    "# Define the loss function\n",
    "loss_fn = nn.MSELoss()  # mean squared error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see how many Parameters our Model has!\n",
    "num_model_params = 0\n",
    "for param in weather_rnn.parameters():\n",
    "    num_model_params += param.flatten().shape[0]\n",
    "\n",
    "print(\"-This Model Has %d (Approximately %d Million) Parameters!\" % (num_model_params, num_model_params//1e6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_loss_logger = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in trange(nepochs, desc=\"Epochs\", leave=False):\n",
    "    weather_rnn.train()\n",
    "    for day, month, data_seq in tqdm(data_loader_train, desc=\"Training\", leave=False):\n",
    "        \n",
    "        # Initialise the buffer with zeros\n",
    "        buffer = torch.zeros(data_seq.shape[0], buffer_size, device=device)\n",
    "        \n",
    "        loss = 0\n",
    "        for i in range(day_range - days_in):\n",
    "            seq_block = data_seq[:, i:(i + days_in)].to(device)\n",
    "            target_seq_block = data_seq[:, i + days_in].to(device)\n",
    "            \n",
    "            # Feed buffer back into network in the next timestep\n",
    "            data_pred, buffer = weather_rnn(seq_block, buffer)\n",
    "            \n",
    "            loss += loss_fn(data_pred, target_seq_block)\n",
    "\n",
    "#             seq_block = torch.cat((seq_block[:, 1:, :], data_pred.unsqueeze(1).detach()), 1)\n",
    "            \n",
    "        loss /= i + 1\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        training_loss_logger.append(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.figure(figsize=(10, 5))\n",
    "_ = plt.plot(training_loss_logger)\n",
    "_ = plt.title(\"Training Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tensor = torch.FloatTensor(dataset_test.dataset.values)\n",
    "\n",
    "log_predictions = []\n",
    "weather_rnn.eval()\n",
    "with torch.no_grad():\n",
    "    buffer = torch.zeros(1, buffer_size, device=device)\n",
    "    for i in range(30):\n",
    "        seq_block = data_tensor[i:(i + days_in), :].unsqueeze(0).to(device)\n",
    "        data_pred, buffer = weather_rnn(seq_block, buffer)\n",
    "        log_predictions.append(data_pred.cpu())\n",
    "        \n",
    "    for j in range(data_tensor.shape[0] - days_in - 30):\n",
    "        seq_block = torch.cat((seq_block[:, 1:, :], data_pred.unsqueeze(1)), 1)\n",
    "        data_pred, buffer = weather_rnn(seq_block, buffer)\n",
    "        log_predictions.append(data_pred.cpu())\n",
    "\n",
    "predictions_cat = torch.cat(log_predictions)\n",
    "un_norm_predictions = (predictions_cat * dataset_test.std) + dataset_test.mean\n",
    "un_norm_data = (data_tensor * dataset_test.std) + dataset_test.mean\n",
    "un_norm_data = un_norm_data[days_in:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mse = (un_norm_data - un_norm_predictions).pow(2).mean().item()\n",
    "print(\"Test MSE value %.2f\" % test_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.figure(figsize=(10, 5))\n",
    "_ = plt.plot(un_norm_data[:, 0])\n",
    "_ = plt.plot(un_norm_predictions[:, 0])\n",
    "_ = plt.title(\"Rainfall (mm)\")\n",
    "\n",
    "_ = plt.legend([\"Ground Truth\", \"Prediction\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.figure(figsize=(10, 10))\n",
    "_ = plt.plot(un_norm_data[:, 1])\n",
    "_ = plt.plot(un_norm_predictions[:, 1])\n",
    "_ = plt.title(\"Max Daily Temperature (C)\")\n",
    "\n",
    "_ = plt.legend([\"Ground Truth\", \"Prediction\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
