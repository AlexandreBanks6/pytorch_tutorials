{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Autoencoder </h1>\n",
    "Autoencoders are a type of unsupervised learning that can be used to compress input data into a lower-dimensional encoding. The objective of training an Auto-Encoder is to create an Encoder that can represent data in a lower-dimensional space, and a Decoder that can take us from this lower-dimensional \"latent\" space back to the original data space.\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/2/28/Autoencoder_structure.png\" width=\"500\" align=\"center\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yhWb2qkq6Idq"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.datasets as Datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "import torchvision.utils as vutils\n",
    "\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import math\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from tqdm.notebook import trange, tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vyfSkLIu6Id3"
   },
   "outputs": [],
   "source": [
    "batchSize = 64\n",
    "\n",
    "# Define learning rate\n",
    "lr = 1e-4\n",
    "\n",
    "# Number of Training epochs\n",
    "nepoch = 10\n",
    "\n",
    "# The size of the Latent Vector\n",
    "latent_size = 128\n",
    "\n",
    "root = \"../../datasets\"\n",
    "\n",
    "noise_scale = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ab2W41mB6Id6"
   },
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "gpu_indx  = 0\n",
    "device = torch.device(gpu_indx if use_cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Create an MNIST dataset and dataloader</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6195,
     "status": "ok",
     "timestamp": 1570409783041,
     "user": {
      "displayName": "Luke Ditria",
      "photoUrl": "",
      "userId": "06313774588804829868"
     },
     "user_tz": -660
    },
    "id": "RJUrSrOl6Id-",
    "outputId": "a37cfcb0-da67-4107-fc85-893028c5d2cf"
   },
   "outputs": [],
   "source": [
    "# Define our transform\n",
    "# We'll upsample the images to 32x32 as it's easier to contruct our network\n",
    "transform = transforms.Compose([\n",
    "            transforms.Resize(32),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.5], [0.5])])\n",
    "\n",
    "train_set = Datasets.MNIST(root=root, train=True, transform=transform, download=True)\n",
    "train_loader = DataLoader(train_set, batch_size=batchSize,shuffle=True, num_workers=4)\n",
    "\n",
    "test_set = Datasets.MNIST(root=root, train=False, transform=transform, download=True)\n",
    "test_loader = DataLoader(test_set, batch_size=batchSize, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LgqQSvQg6IeG"
   },
   "source": [
    "## AE Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v-TN2KYN6IeH"
   },
   "outputs": [],
   "source": [
    "# We split up our network into two parts, the Encoder and the Decoder\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, channels, ch=32, z=32):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(channels, ch, 4, 2, 1)\n",
    "        self.bn1 = nn.BatchNorm2d(ch)\n",
    "        self.conv2 = nn.Conv2d(ch, 2*ch, 4, 2, 1)\n",
    "        self.bn2 = nn.BatchNorm2d(2*ch)\n",
    "        self.conv3 = nn.Conv2d(2*ch, 4*ch, 4, 2, 1)\n",
    "        self.bn3 = nn.BatchNorm2d(4*ch)\n",
    "\n",
    "        self.conv_out = nn.Conv2d(4*ch, z, 4, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "\n",
    "        return self.conv_out(x)\n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, channels, ch = 32, z = 32):\n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.ConvTranspose2d(z, 4*ch, 4, 1)\n",
    "        self.bn1 = nn.BatchNorm2d(4*ch)\n",
    "        self.conv2 = nn.ConvTranspose2d(4*ch, 2*ch, 4, 2, 1)\n",
    "        self.bn2 = nn.BatchNorm2d(2*ch)\n",
    "        self.conv3 = nn.ConvTranspose2d(2*ch, ch, 4, 2, 1)\n",
    "        self.bn3 = nn.BatchNorm2d(ch)\n",
    "        self.conv4 = nn.ConvTranspose2d(ch, channels, 4, 2, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = self.conv4(x)\n",
    "\n",
    "        return torch.tanh(x)\n",
    "    \n",
    "class AE(nn.Module):\n",
    "    def __init__(self, channel_in, ch=16, z=32):\n",
    "        super(AE, self).__init__()\n",
    "        self.encoder = Encoder(channels=channel_in, ch=ch, z=z)\n",
    "        self.decoder = Decoder(channels=channel_in, ch=ch, z=z)\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoding = self.encoder(x)\n",
    "        x = self.decoder(encoding)\n",
    "        return x, encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Visualize our data</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6489,
     "status": "ok",
     "timestamp": 1570409783350,
     "user": {
      "displayName": "Luke Ditria",
      "photoUrl": "",
      "userId": "06313774588804829868"
     },
     "user_tz": -660
    },
    "id": "74l6KlI06IeK",
    "outputId": "8d7a863d-8de8-4ae0-c4c1-403ddb67eae5"
   },
   "outputs": [],
   "source": [
    "# Get a test image\n",
    "dataiter = iter(test_loader)\n",
    "test_images = dataiter.next()[0]\n",
    "# View the shape\n",
    "test_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7133,
     "status": "ok",
     "timestamp": 1570409784001,
     "user": {
      "displayName": "Luke Ditria",
      "photoUrl": "",
      "userId": "06313774588804829868"
     },
     "user_tz": -660
    },
    "id": "GBE2TPmy6IeN",
    "outputId": "8344a523-4b6a-4adb-ecdd-c59fd617b137"
   },
   "outputs": [],
   "source": [
    "# Visualize the data!!!\n",
    "plt.figure(figsize = (20,10))\n",
    "out = vutils.make_grid(test_images[0:8], normalize=True)\n",
    "_ = plt.imshow(out.numpy().transpose((1, 2, 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### De-noising Autoencoder\n",
    "Lets use the auto encoder architecture to remove some noise from an image!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the data!!!\n",
    "plt.figure(figsize = (20, 10))\n",
    "random_sample = (torch.bernoulli((1 - noise_scale) * torch.ones_like(test_images)) * 2) - 1\n",
    "noisy_test_img = random_sample * test_images\n",
    "\n",
    "out = vutils.make_grid(noisy_test_img[0:8], normalize=True)\n",
    "_ = plt.imshow(out.numpy().transpose((1, 2, 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Create Network and Optimizer</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XuZmm4Jx6IeQ"
   },
   "outputs": [],
   "source": [
    "# Create our network\n",
    "ae_net = AE(channel_in=1, z=latent_size).to(device)\n",
    "# Setup optimizer\n",
    "optimizer = optim.Adam(ae_net.parameters(), lr=lr)\n",
    "\n",
    "loss_func = nn.MSELoss()\n",
    "\n",
    "loss_log = []\n",
    "train_loss = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Network output</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7126,
     "status": "ok",
     "timestamp": 1570409784003,
     "user": {
      "displayName": "Luke Ditria",
      "photoUrl": "",
      "userId": "06313774588804829868"
     },
     "user_tz": -660
    },
    "id": "iteROyrA6IeT",
    "outputId": "51104e6b-af60-44b9-a7f6-5885749d92af"
   },
   "outputs": [],
   "source": [
    "# Pass through a test image to make sure everything is working\n",
    "recon_data, encoding = ae_net(test_images.to(device))\n",
    "\n",
    "# View the Latent vector shape\n",
    "encoding.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Start training!</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1570410601202,
     "user": {
      "displayName": "Luke Ditria",
      "photoUrl": "",
      "userId": "06313774588804829868"
     },
     "user_tz": -660
    },
    "id": "bVFA6W6L6IeY",
    "outputId": "99cd69e0-8ff6-466b-fb59-4e4ba9f33271"
   },
   "outputs": [],
   "source": [
    "pbar = trange(0, nepoch, leave=False, desc=\"Epoch\")    \n",
    "for epoch in pbar:\n",
    "    pbar.set_postfix_str('Loss: %.4f' % train_loss)\n",
    "    for i, data in enumerate(tqdm(train_loader, leave=False, desc=\"Training\")):\n",
    "\n",
    "        image = data[0].to(device)\n",
    "        \n",
    "        random_sample = (torch.bernoulli((1 - noise_scale) * torch.ones_like(image)) * 2) - 1\n",
    "        noisy_img = random_sample * image\n",
    "        \n",
    "        # Forward pass the image in the data tuple\n",
    "        recon_data, _ = ae_net(noisy_img)\n",
    "        \n",
    "        # Calculate the MSE loss\n",
    "        loss = loss_func(recon_data, image)\n",
    "        \n",
    "        # Log the loss\n",
    "        loss_log.append(loss.item())\n",
    "        train_loss = loss.item()\n",
    "        \n",
    "        # Take a training step\n",
    "        ae_net.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N0ZrSDsR6Ief"
   },
   "source": [
    "## Results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 824609,
     "status": "ok",
     "timestamp": 1570410601500,
     "user": {
      "displayName": "Luke Ditria",
      "photoUrl": "",
      "userId": "06313774588804829868"
     },
     "user_tz": -660
    },
    "id": "vTr64GEm6Iej",
    "outputId": "4d715e03-42e0-4277-ec5a-1e5577c2b240"
   },
   "outputs": [],
   "source": [
    "_ = plt.plot(loss_log)\n",
    "_ = plt.title(\"MSE Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 825552,
     "status": "ok",
     "timestamp": 1570410602450,
     "user": {
      "displayName": "Luke Ditria",
      "photoUrl": "",
      "userId": "06313774588804829868"
     },
     "user_tz": -660
    },
    "id": "yqC3cmVx6Ieo",
    "outputId": "8665a80d-bc7d-4be4-d8fa-89716e7391c7"
   },
   "outputs": [],
   "source": [
    "# Ground Truth\n",
    "plt.figure(figsize = (20,10))\n",
    "out = vutils.make_grid(test_images[0:8], normalize=True)\n",
    "_ = plt.imshow(out.numpy().transpose((1, 2, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Noisy Input\n",
    "plt.figure(figsize = (20,10))\n",
    "out = vutils.make_grid(noisy_test_img[0:8], normalize=True)\n",
    "_ = plt.imshow(out.numpy().transpose((1, 2, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 825546,
     "status": "ok",
     "timestamp": 1570410602451,
     "user": {
      "displayName": "Luke Ditria",
      "photoUrl": "",
      "userId": "06313774588804829868"
     },
     "user_tz": -660
    },
    "id": "kX95LD-u6Iet",
    "outputId": "40c30d2b-837b-4143-a540-024b14789389"
   },
   "outputs": [],
   "source": [
    "# Reconstruction\n",
    "plt.figure(figsize = (20,10))\n",
    "recon_data, _ = ae_net(noisy_test_img.to(device))\n",
    "out = vutils.make_grid(recon_data.detach().cpu()[0:8], normalize=True)\n",
    "_ = plt.imshow(out.numpy().transpose((1, 2, 0)))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "VAE.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
